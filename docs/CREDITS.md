# Credits:
## Development team:
1. â­ [Nikita Selin (Anodev) (OPHoperHPO)](https://github.com/OPHoperHPO) - Project Leader - **The main part of the functional**
## Contributors:
1. [Munawwar](https://github.com/Munawwar) - [GUI](https://github.com/OPHoperHPO/image-background-remove-tool/pull/10) > *Already deprecated and removed, because it was completely rewritten.*
2. [Pubkey](https://github.com/pubkey) - [Add docker build, Improve http_api](https://github.com/OPHoperHPO/image-background-remove-tool/pull/25)
3. [chris-rgr](https://github.com/chris-rgr) - [Loading models via absolute path](https://github.com/OPHoperHPO/image-background-remove-tool/pull/28)

## Disclaimer for pretrained Models:
All rights to the pretrained models used in this project belong to their authors. \
I do not vouch for their quality and do not claim to be licensed to use any model. \
It is your responsibility to determine if you have permission to use the pretrained model under the license for the dataset it was trained on or licensed under. \
Any use of the pretrained model is strictly regulated by the licenses under which the model is distributed. \
If you own the model and want to update it (file, segmentation quality information, etc.) or don't want your model to be included in this tool, please get in touch through a GitHub issue.
## Icons:
The GUI uses icons from the [Google Material Design Icons pack](https://github.com/google/material-design-icons/). \
These images are licensed under the Apache License 2.0.
## Photos:
The photos in the `docs/imgs/input/` and `docs/code_examples/python/input/` folders were taken from the Pexels website. \
The original photos in the `docs/imgs/compare` folder were taken from the Unsplash site. \
All images are copyrighted by their authors.

## References:
1. https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/
2. https://github.com/NathanUA/U-2-Net
3. https://github.com/NathanUA/BASNet
4. https://github.com/MarcoForte/FBA_Matting
5. https://gluon-cv.mxnet.io/model_zoo/detection.html
6. https://arxiv.org/abs/1706.05587
7. https://arxiv.org/pdf/2005.09007.pdf
8. http://openaccess.thecvf.com/content_CVPR_2019/html/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html
9. https://arxiv.org/abs/2003.07711
10. https://arxiv.org/abs/1506.01497
11. https://arxiv.org/abs/1703.06870